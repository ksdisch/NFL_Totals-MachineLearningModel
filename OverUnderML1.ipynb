{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c845d9a7",
   "metadata": {},
   "source": [
    "# NFL Over Under Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a967339",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f3f492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae053e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>team_home_full</th>\n",
       "      <th>team_home_abrv</th>\n",
       "      <th>team_home_combined</th>\n",
       "      <th>team_away_full</th>\n",
       "      <th>team_away_abrv</th>\n",
       "      <th>team_away_combined</th>\n",
       "      <th>...</th>\n",
       "      <th>dvoa_overall_cumulative</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_weighted_cumulative</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>dvoa_dave_cumulative</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>dvoa_off_cumulative</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>dvoa_def_cumulative</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353</td>\n",
       "      <td>12/2/2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>Jacksonville Jaguars</td>\n",
       "      <td>JAX</td>\n",
       "      <td>JAX2018</td>\n",
       "      <td>Indianapolis Colts</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.053</td>\n",
       "      <td>29.55125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4900</td>\n",
       "      <td>12/3/2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>CAR</td>\n",
       "      <td>CAR2000</td>\n",
       "      <td>St. Louis Rams</td>\n",
       "      <td>LAR</td>\n",
       "      <td>LAR2000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.028</td>\n",
       "      <td>29.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>12/19/2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB2021</td>\n",
       "      <td>New Orleans Saints</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO2021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>28.77750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2364</td>\n",
       "      <td>12/12/2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET2010</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.002</td>\n",
       "      <td>29.62250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3150</td>\n",
       "      <td>11/26/2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>PIT</td>\n",
       "      <td>PIT2007</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>MIA2007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>30.38250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date  year  week        team_home_full team_home_abrv  \\\n",
       "0    353   12/2/2018  2018    13  Jacksonville Jaguars            JAX   \n",
       "1   4900   12/3/2000  2000    14     Carolina Panthers            CAR   \n",
       "2     61  12/19/2021  2021    15  Tampa Bay Buccaneers             TB   \n",
       "3   2364  12/12/2010  2010    14         Detroit Lions            DET   \n",
       "4   3150  11/26/2007  2007    12   Pittsburgh Steelers            PIT   \n",
       "\n",
       "  team_home_combined      team_away_full team_away_abrv team_away_combined  \\\n",
       "0            JAX2018  Indianapolis Colts            IND            IND2018   \n",
       "1            CAR2000      St. Louis Rams            LAR            LAR2000   \n",
       "2             TB2021  New Orleans Saints             NO             NO2021   \n",
       "3            DET2010   Green Bay Packers             GB             GB2010   \n",
       "4            PIT2007      Miami Dolphins            MIA            MIA2007   \n",
       "\n",
       "   ...  dvoa_overall_cumulative  dvoa_weighted_diff  dvoa_weighted_cumulative  \\\n",
       "0  ...                    0.039              -0.365                     0.081   \n",
       "1  ...                   -0.030              -0.362                    -0.052   \n",
       "2  ...                    0.323               0.261                     0.257   \n",
       "3  ...                    0.256              -0.174                     0.306   \n",
       "4  ...                   -0.040               0.361                    -0.193   \n",
       "\n",
       "   dvoa_dave_diff  dvoa_dave_cumulative  team_home_dvoa_off_diff  \\\n",
       "0          -0.296                -0.138                   -0.097   \n",
       "1          -0.449                 0.091                    0.044   \n",
       "2           0.373                 0.161                   -0.036   \n",
       "3          -0.125                 0.113                    0.022   \n",
       "4           0.148                 0.014                   -0.100   \n",
       "\n",
       "  dvoa_off_cumulative  team_away_dvoa_off_diff  dvoa_def_cumulative  \\\n",
       "0              -0.123                    0.079                0.053   \n",
       "1               0.148                   -0.076                0.028   \n",
       "2              -0.183                    0.126               -0.021   \n",
       "3              -0.142                    0.166                0.002   \n",
       "4               0.011                   -0.154               -0.043   \n",
       "\n",
       "   comp_pace_avg  \n",
       "0       29.55125  \n",
       "1       29.46875  \n",
       "2       28.77750  \n",
       "3       29.62250  \n",
       "4       30.38250  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = Path('nfl.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ac0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>over_under</th>\n",
       "      <th>favorite_spread</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>team_home_off_pace_neutral</th>\n",
       "      <th>team_home_def_pace_neutral</th>\n",
       "      <th>team_home_off_pace_total</th>\n",
       "      <th>team_home_def_pace_total</th>\n",
       "      <th>team_home_comp_pace</th>\n",
       "      <th>...</th>\n",
       "      <th>dvoa_overall_cumulative</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_weighted_cumulative</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>dvoa_dave_cumulative</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>dvoa_off_cumulative</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>dvoa_def_cumulative</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>45.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>32.27</td>\n",
       "      <td>31.60</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.60</td>\n",
       "      <td>30.1625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.053</td>\n",
       "      <td>29.55125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>30.56</td>\n",
       "      <td>30.57</td>\n",
       "      <td>27.81</td>\n",
       "      <td>27.96</td>\n",
       "      <td>29.2250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.028</td>\n",
       "      <td>29.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>45.5</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>28.66</td>\n",
       "      <td>30.42</td>\n",
       "      <td>26.58</td>\n",
       "      <td>27.04</td>\n",
       "      <td>28.1750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>28.77750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>29.57</td>\n",
       "      <td>32.07</td>\n",
       "      <td>26.15</td>\n",
       "      <td>28.71</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.002</td>\n",
       "      <td>29.62250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>38.5</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>33.94</td>\n",
       "      <td>30.31</td>\n",
       "      <td>31.31</td>\n",
       "      <td>27.02</td>\n",
       "      <td>30.6450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>30.38250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   week  over_under  favorite_spread  temperature  wind_mph  \\\n",
       "0    13        45.5             -4.0           78        13   \n",
       "1    14        58.0             -8.0           35        13   \n",
       "2    15        45.5            -11.5           75         0   \n",
       "3    14        46.0             -7.0           72         0   \n",
       "4    12        38.5            -16.0           46         7   \n",
       "\n",
       "   team_home_off_pace_neutral  team_home_def_pace_neutral  \\\n",
       "0                       32.27                       31.60   \n",
       "1                       30.56                       30.57   \n",
       "2                       28.66                       30.42   \n",
       "3                       29.57                       32.07   \n",
       "4                       33.94                       30.31   \n",
       "\n",
       "   team_home_off_pace_total  team_home_def_pace_total  team_home_comp_pace  \\\n",
       "0                     28.18                     28.60              30.1625   \n",
       "1                     27.81                     27.96              29.2250   \n",
       "2                     26.58                     27.04              28.1750   \n",
       "3                     26.15                     28.71              29.1250   \n",
       "4                     31.31                     27.02              30.6450   \n",
       "\n",
       "   ...  dvoa_overall_cumulative  dvoa_weighted_diff  dvoa_weighted_cumulative  \\\n",
       "0  ...                    0.039              -0.365                     0.081   \n",
       "1  ...                   -0.030              -0.362                    -0.052   \n",
       "2  ...                    0.323               0.261                     0.257   \n",
       "3  ...                    0.256              -0.174                     0.306   \n",
       "4  ...                   -0.040               0.361                    -0.193   \n",
       "\n",
       "   dvoa_dave_diff  dvoa_dave_cumulative  team_home_dvoa_off_diff  \\\n",
       "0          -0.296                -0.138                   -0.097   \n",
       "1          -0.449                 0.091                    0.044   \n",
       "2           0.373                 0.161                   -0.036   \n",
       "3          -0.125                 0.113                    0.022   \n",
       "4           0.148                 0.014                   -0.100   \n",
       "\n",
       "   dvoa_off_cumulative  team_away_dvoa_off_diff  dvoa_def_cumulative  \\\n",
       "0               -0.123                    0.079                0.053   \n",
       "1                0.148                   -0.076                0.028   \n",
       "2               -0.183                    0.126               -0.021   \n",
       "3               -0.142                    0.166                0.002   \n",
       "4                0.011                   -0.154               -0.043   \n",
       "\n",
       "   comp_pace_avg  \n",
       "0       29.55125  \n",
       "1       29.46875  \n",
       "2       28.77750  \n",
       "3       29.62250  \n",
       "4       30.38250  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target variable and drop irrelevant columns for ML\n",
    "y = df['over_binary']\n",
    "X = df.drop(columns=['index','over_binary', 'over_under_diff', 'score_total', 'date', 'team_home_full', 'team_home_abrv', 'team_home_combined',\n",
    "                     'team_away_full', 'team_away_abrv', 'team_away_combined',\n",
    "                     'team_favorite_abrv', 'weather_detail', 'score_home', 'score_away', 'dome_binary',\n",
    "                     'humidity', 'year'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedc033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3754, 38)\n",
      "(1252, 38)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278dbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a Standard Scaler with the training data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# ccaling the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadfb497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21292306 0.18605225 0.11717091 0.07500212 0.06486438]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006357</td>\n",
       "      <td>-3.372389</td>\n",
       "      <td>-2.341359</td>\n",
       "      <td>1.529963</td>\n",
       "      <td>-2.112368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.824218</td>\n",
       "      <td>0.016659</td>\n",
       "      <td>0.490613</td>\n",
       "      <td>-2.198270</td>\n",
       "      <td>0.463107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.610773</td>\n",
       "      <td>1.769707</td>\n",
       "      <td>0.617033</td>\n",
       "      <td>-2.584112</td>\n",
       "      <td>0.601413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.398133</td>\n",
       "      <td>-3.340851</td>\n",
       "      <td>3.097917</td>\n",
       "      <td>1.788106</td>\n",
       "      <td>-2.774951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.104400</td>\n",
       "      <td>1.890704</td>\n",
       "      <td>1.187550</td>\n",
       "      <td>1.771458</td>\n",
       "      <td>2.623311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>0.878740</td>\n",
       "      <td>-2.261592</td>\n",
       "      <td>-0.778978</td>\n",
       "      <td>-1.413046</td>\n",
       "      <td>0.064834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>-3.497528</td>\n",
       "      <td>0.078239</td>\n",
       "      <td>4.707023</td>\n",
       "      <td>-1.731371</td>\n",
       "      <td>-2.981197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>0.233319</td>\n",
       "      <td>3.888571</td>\n",
       "      <td>-2.617679</td>\n",
       "      <td>-0.603177</td>\n",
       "      <td>0.665065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>-3.039212</td>\n",
       "      <td>1.519386</td>\n",
       "      <td>-1.106635</td>\n",
       "      <td>-0.568822</td>\n",
       "      <td>-3.797712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>1.235408</td>\n",
       "      <td>-3.290737</td>\n",
       "      <td>-2.698735</td>\n",
       "      <td>-0.379543</td>\n",
       "      <td>0.051370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3754 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "0    -0.006357 -3.372389 -2.341359  1.529963 -2.112368\n",
       "1    -5.824218  0.016659  0.490613 -2.198270  0.463107\n",
       "2    -1.610773  1.769707  0.617033 -2.584112  0.601413\n",
       "3     3.398133 -3.340851  3.097917  1.788106 -2.774951\n",
       "4     6.104400  1.890704  1.187550  1.771458  2.623311\n",
       "...        ...       ...       ...       ...       ...\n",
       "3749  0.878740 -2.261592 -0.778978 -1.413046  0.064834\n",
       "3750 -3.497528  0.078239  4.707023 -1.731371 -2.981197\n",
       "3751  0.233319  3.888571 -2.617679 -0.603177  0.665065\n",
       "3752 -3.039212  1.519386 -1.106635 -0.568822 -3.797712\n",
       "3753  1.235408 -3.290737 -2.698735 -0.379543  0.051370\n",
       "\n",
       "[3754 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train_scaled)\n",
    "pca.fit(X_test_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "df_pca = pd.DataFrame(X_train_pca)\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52a301",
   "metadata": {},
   "source": [
    "## ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928700a1",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c26370a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b98dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>358</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>277</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              358             274\n",
       "Actual Over               277             343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5599041533546326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57       632\n",
      "           1       0.56      0.55      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "logreg_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {logreg_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e9898",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6545807a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Perceptron(random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "006713f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>340</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>314</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              340             292\n",
       "Actual Over               314             306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5159744408945687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.54      0.53       632\n",
      "           1       0.51      0.49      0.50       620\n",
      "\n",
      "    accuracy                           0.52      1252\n",
      "   macro avg       0.52      0.52      0.52      1252\n",
      "weighted avg       0.52      0.52      0.52      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "percep_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {percep_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a01b7",
   "metadata": {},
   "source": [
    "### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24926380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = PassiveAggressiveClassifier(random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b1eb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>367</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>348</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              367             265\n",
       "Actual Over               348             272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5103833865814696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.54       632\n",
      "           1       0.51      0.44      0.47       620\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.51      0.51      0.51      1252\n",
      "weighted avg       0.51      0.51      0.51      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "pasagres_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {pasagres_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a35372",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db81ab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RidgeClassifier(alpha=1, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05fa864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>359</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>278</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              359             273\n",
       "Actual Over               278             342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5599041533546326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57       632\n",
      "           1       0.56      0.55      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "ridge_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {ridge_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bef20a",
   "metadata": {},
   "source": [
    "### Suppor Vector Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0237b51",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd9c0b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d6a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>360</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>280</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              360             272\n",
       "Actual Over               280             340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5591054313099042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57       632\n",
      "           1       0.56      0.55      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "linsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {linsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f8fff",
   "metadata": {},
   "source": [
    "#### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a702a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=2, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(gamma=2, C=1, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53d374ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              632               0\n",
       "Actual Over               620               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5047923322683706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       632\n",
      "           1       0.00      0.00      0.00       620\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.25      0.50      0.34      1252\n",
      "weighted avg       0.25      0.50      0.34      1252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "rbfsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {rbfsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd279452",
   "metadata": {},
   "source": [
    "### Nu-Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c6f58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVC(nu=0.1, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NuSVC(random_state=0, nu=0.1, kernel='rbf')\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9218e3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>336</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>291</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              336             296\n",
       "Actual Over               291             329"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5311501597444089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53       632\n",
      "           1       0.53      0.53      0.53       620\n",
      "\n",
      "    accuracy                           0.53      1252\n",
      "   macro avg       0.53      0.53      0.53      1252\n",
      "weighted avg       0.53      0.53      0.53      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nusvc_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nusvc_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18d584",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed67526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tree.DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f89fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>325</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>313</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              325             307\n",
       "Actual Over               313             307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5047923322683706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51       632\n",
      "           1       0.50      0.50      0.50       620\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.50      0.50      0.50      1252\n",
      "weighted avg       0.50      0.50      0.50      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "decision_tree_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {decision_tree_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463d68a",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3821906",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=512, random_state=0)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76912074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>325</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>313</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              325             307\n",
       "Actual Over               313             307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5047923322683706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51       632\n",
      "           1       0.50      0.50      0.50       620\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.50      0.50      0.50      1252\n",
      "weighted avg       0.50      0.50      0.50      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "randforest_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {randforest_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63db9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.033776073424256654, 'over_under'),\n",
       " (0.031353281730844465, 'dvoa_dave_cumulative'),\n",
       " (0.031053835673447387, 'team_home_dvoa_off_diff'),\n",
       " (0.030621648392446875, 'comp_pace_avg'),\n",
       " (0.030107010600478157, 'dvoa_off_cumulative'),\n",
       " (0.02986612191984152, 'team_away_dvoa_off_diff'),\n",
       " (0.028890197907224767, 'dvoa_def_cumulative'),\n",
       " (0.028234123273645908, 'team_home_def_pace_total'),\n",
       " (0.028032766959810808, 'team_away_dvoa_offense'),\n",
       " (0.027700442778518932, 'dvoa_weighted_cumulative'),\n",
       " (0.027678285548956964, 'team_away_off_pace_neutral'),\n",
       " (0.027571719167497375, 'dvoa_overall_cumulative'),\n",
       " (0.027389088652261764, 'team_home_def_pace_neutral'),\n",
       " (0.02715535486433128, 'team_away_off_pace_total'),\n",
       " (0.02715384908086326, 'team_away_def_pace_neutral'),\n",
       " (0.026672916359431417, 'dvoa_dave_diff'),\n",
       " (0.026430122114199272, 'team_away_def_pace_total'),\n",
       " (0.026417001118478223, 'dvoa_weighted_diff'),\n",
       " (0.02640884502666093, 'team_home_dvoa_defense'),\n",
       " (0.02633209661109279, 'team_away_comp_pace'),\n",
       " (0.02621255021463044, 'team_home_off_pace_total'),\n",
       " (0.026061096328855757, 'dvoa_overall_diff'),\n",
       " (0.02605584998382843, 'team_home_off_pace_neutral'),\n",
       " (0.026031248576204154, 'team_away_dvoa_defense'),\n",
       " (0.02583663657327198, 'team_home_dvoa_offense'),\n",
       " (0.0258278736257747, 'temperature'),\n",
       " (0.025363415819924705, 'team_home_comp_pace'),\n",
       " (0.024518692555782144, 'team_away_dvoa_dave'),\n",
       " (0.024178526949574536, 'team_home_dvoa_dave'),\n",
       " (0.023837741434937467, 'favorite_spread'),\n",
       " (0.023612252094759673, 'week'),\n",
       " (0.02345978825537308, 'team_home_dvoa_weighted'),\n",
       " (0.022571257292169578, 'team_away_dvoa_weighted'),\n",
       " (0.022492458195281347, 'team_home_dvoa_overall'),\n",
       " (0.021672973007829135, 'team_home_dvoa_special'),\n",
       " (0.02156737024105288, 'team_away_dvoa_overall'),\n",
       " (0.021230645679798127, 'wind_mph'),\n",
       " (0.020624841966662893, 'team_away_dvoa_special')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c739b",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5519fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_features=5, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=50,\n",
    "   learning_rate=0.1, max_features=5, max_depth=3, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5074c406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>372</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>272</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              372             260\n",
       "Actual Over               272             348"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5750798722044729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.58       632\n",
      "           1       0.57      0.56      0.57       620\n",
      "\n",
      "    accuracy                           0.58      1252\n",
      "   macro avg       0.58      0.57      0.57      1252\n",
      "weighted avg       0.58      0.58      0.58      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gradboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gradboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42782c78",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e55d40b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.53, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators = 200,\n",
    "                                learning_rate = 0.53,\n",
    "                                random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e5aa839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>352</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>277</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              352             280\n",
       "Actual Over               277             343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.555111821086262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       632\n",
      "           1       0.55      0.55      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "adaboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {adaboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0265167",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ada48207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_samples=200, n_estimators=2000, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BaggingClassifier(n_estimators = 2000,\n",
    "                               max_samples = 200, \n",
    "                               random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a8e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>353</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>290</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              353             279\n",
       "Actual Over               290             330"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5455271565495208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55       632\n",
      "           1       0.54      0.53      0.54       620\n",
      "\n",
      "    accuracy                           0.55      1252\n",
      "   macro avg       0.55      0.55      0.55      1252\n",
      "weighted avg       0.55      0.55      0.55      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "bag_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {bag_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0100a",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e543eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(criterion='entropy', n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = ExtraTreesClassifier(n_estimators=300,\n",
    "                                 criterion='entropy',\n",
    "                                 random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7f598c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>363</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>323</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              363             269\n",
       "Actual Over               323             297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5271565495207667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55       632\n",
      "           1       0.52      0.48      0.50       620\n",
      "\n",
      "    accuracy                           0.53      1252\n",
      "   macro avg       0.53      0.53      0.53      1252\n",
      "weighted avg       0.53      0.53      0.53      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "extratrees_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {extratrees_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee98370",
   "metadata": {},
   "source": [
    "### Histogram Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4f83227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = HistGradientBoostingClassifier(loss='auto',\n",
    "                                           learning_rate=0.1,\n",
    "                                           max_iter=100,\n",
    "                                           random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19910967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>348</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>303</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              348             284\n",
       "Actual Over               303             317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5311501597444089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54       632\n",
      "           1       0.53      0.51      0.52       620\n",
      "\n",
      "    accuracy                           0.53      1252\n",
      "   macro avg       0.53      0.53      0.53      1252\n",
      "weighted avg       0.53      0.53      0.53      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "histgrad_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {histgrad_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a38360",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e2c85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec3b5ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>400</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>339</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              400             232\n",
       "Actual Over               339             281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5439297124600639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58       632\n",
      "           1       0.55      0.45      0.50       620\n",
      "\n",
      "    accuracy                           0.54      1252\n",
      "   macro avg       0.54      0.54      0.54      1252\n",
      "weighted avg       0.54      0.54      0.54      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nbayes_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nbayes_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5dd9b",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84f854ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearDiscriminantAnalysis(solver='svd') # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6195bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>366</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>261</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              366             266\n",
       "Actual Over               261             359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.579073482428115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       632\n",
      "           1       0.57      0.58      0.58       620\n",
      "\n",
      "    accuracy                           0.58      1252\n",
      "   macro avg       0.58      0.58      0.58      1252\n",
      "weighted avg       0.58      0.58      0.58      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "lda_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {lda_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b105186",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7494c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = QuadraticDiscriminantAnalysis() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc286b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>333</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>319</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              333             299\n",
       "Actual Over               319             301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5063897763578274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.53      0.52       632\n",
      "           1       0.50      0.49      0.49       620\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.51      0.51      0.51      1252\n",
      "weighted avg       0.51      0.51      0.51      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "qda_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {qda_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633f368",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf34c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(4, leaf_size=30) # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52962dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>455</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>422</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              455             177\n",
       "Actual Over               422             198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5215654952076677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.72      0.60       632\n",
      "           1       0.53      0.32      0.40       620\n",
      "\n",
      "    accuracy                           0.52      1252\n",
      "   macro avg       0.52      0.52      0.50      1252\n",
      "weighted avg       0.52      0.52      0.50      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nearneighboor_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nearneighboor_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ed1f8",
   "metadata": {},
   "source": [
    "### Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e8437fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(kernel=RBF(length_scale=1), random_state=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianProcessClassifier(RBF(1.0), random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fc8cacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>378</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>292</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              378             254\n",
       "Actual Over               292             328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5638977635782748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58       632\n",
      "           1       0.56      0.53      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gausprocess_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gausprocess_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6662a",
   "metadata": {},
   "source": [
    "### MLP Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1497e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(alpha=1, max_iter=1000, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77f92572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>365</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>284</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              365             267\n",
       "Actual Over               284             336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5599041533546326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       632\n",
      "           1       0.56      0.54      0.55       620\n",
      "\n",
      "    accuracy                           0.56      1252\n",
      "   macro avg       0.56      0.56      0.56      1252\n",
      "weighted avg       0.56      0.56      0.56      1252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "mlp_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {mlp_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6172b7",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "59ac4583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_101 (Dense)           (None, 4)                 156       \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/80\n",
      "118/118 [==============================] - 1s 2ms/step - loss: 0.6994 - accuracy: 0.5085\n",
      "Epoch 2/80\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5232\n",
      "Epoch 3/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5304\n",
      "Epoch 4/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5381\n",
      "Epoch 5/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5418\n",
      "Epoch 6/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.5421\n",
      "Epoch 7/80\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6882 - accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5551\n",
      "Epoch 9/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5543\n",
      "Epoch 10/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5551\n",
      "Epoch 11/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5581\n",
      "Epoch 12/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5639\n",
      "Epoch 13/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.5706\n",
      "Epoch 14/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5754\n",
      "Epoch 15/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5751\n",
      "Epoch 16/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.5778\n",
      "Epoch 17/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5796\n",
      "Epoch 18/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6787 - accuracy: 0.5839\n",
      "Epoch 19/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5834\n",
      "Epoch 20/80\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6772 - accuracy: 0.5876\n",
      "Epoch 21/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5887\n",
      "Epoch 22/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5860\n",
      "Epoch 23/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5898\n",
      "Epoch 24/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5911\n",
      "Epoch 25/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5863\n",
      "Epoch 26/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5876\n",
      "Epoch 27/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5922\n",
      "Epoch 28/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.5919\n",
      "Epoch 29/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.5932\n",
      "Epoch 30/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.5964\n",
      "Epoch 31/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.5946\n",
      "Epoch 32/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.5908\n",
      "Epoch 33/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5919\n",
      "Epoch 34/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5954\n",
      "Epoch 35/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.5879\n",
      "Epoch 36/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.5932\n",
      "Epoch 37/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5951\n",
      "Epoch 38/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 0.5951\n",
      "Epoch 39/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5948\n",
      "Epoch 40/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.5924\n",
      "Epoch 41/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5954\n",
      "Epoch 42/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.5938\n",
      "Epoch 43/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5930\n",
      "Epoch 44/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5938\n",
      "Epoch 45/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.5954\n",
      "Epoch 46/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5970\n",
      "Epoch 47/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.5964\n",
      "Epoch 48/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5927\n",
      "Epoch 49/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.5972\n",
      "Epoch 50/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.5986\n",
      "Epoch 51/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5970\n",
      "Epoch 52/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6677 - accuracy: 0.5956\n",
      "Epoch 53/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.5994\n",
      "Epoch 54/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.6002\n",
      "Epoch 55/80\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6677 - accuracy: 0.5972\n",
      "Epoch 56/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6007\n",
      "Epoch 57/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5954\n",
      "Epoch 58/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.6004\n",
      "Epoch 59/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.6023\n",
      "Epoch 60/80\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6668 - accuracy: 0.6018\n",
      "Epoch 61/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6002\n",
      "Epoch 62/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6036\n",
      "Epoch 63/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.5996\n",
      "Epoch 64/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6031\n",
      "Epoch 65/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.5983\n",
      "Epoch 66/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.6015\n",
      "Epoch 67/80\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.6659 - accuracy: 0.6023\n",
      "Epoch 68/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.6004\n",
      "Epoch 69/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.6028\n",
      "Epoch 70/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.5988\n",
      "Epoch 71/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6010\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6018\n",
      "Epoch 73/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6010\n",
      "Epoch 74/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6018\n",
      "Epoch 75/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6012\n",
      "Epoch 76/80\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6018\n",
      "Epoch 77/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6018\n",
      "Epoch 78/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.6015\n",
      "Epoch 79/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.5970\n",
      "Epoch 80/80\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6002\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "nodes_hidden_layer1 = 4\n",
    "nodes_hidden_layer2 = 2\n",
    "nn = tf.keras.models.Sequential()\n",
    "dense = tf.keras.layers.Dense(2, kernel_regularizer='l1_l2')\n",
    "\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer1, activation='relu', input_dim=number_input_features))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer2, activation='relu'))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "print(nn.summary())\n",
    "\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "os.makedirs(\"checkpoints_optimization_change_activ/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_optimization_change_activ/weights.{epoch:02d}hdf5\"\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=80, callbacks=[cp_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0d8a9da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.6871 - accuracy: 0.5623 - 271ms/epoch - 7ms/step\n",
      "Loss: 0.6871472597122192, Accuracy: 0.5623003244400024\n"
     ]
    }
   ],
   "source": [
    "model_loss, nn_acc_score = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {nn_acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06163c25",
   "metadata": {},
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61bf765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.559904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.515974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAgressive</th>\n",
       "      <td>0.510383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.559904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.559105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.504792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSupport SVC</th>\n",
       "      <td>0.531150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.504792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.504792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.575080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.555112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.545527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees</th>\n",
       "      <td>0.527157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hist Gradient Boost</th>\n",
       "      <td>0.531150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.543930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.579073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.506390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <td>0.521565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process</th>\n",
       "      <td>0.563898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Neural Net</th>\n",
       "      <td>0.559904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Neural Net</th>\n",
       "      <td>0.562300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "LogReg               0.559904\n",
       "Perceptron           0.515974\n",
       "PassiveAgressive     0.510383\n",
       "Ridge                0.559904\n",
       "Linear SVM           0.559105\n",
       "RBF SVM              0.504792\n",
       "NuSupport SVC        0.531150\n",
       "Decision Tree        0.504792\n",
       "Random Forest        0.504792\n",
       "Gradient Boosting    0.575080\n",
       "AdaBoost             0.555112\n",
       "Bagging              0.545527\n",
       "Extra Trees          0.527157\n",
       "Hist Gradient Boost  0.531150\n",
       "Naive Bayes          0.543930\n",
       "LDA                  0.579073\n",
       "QDA                  0.506390\n",
       "Nearest Neighbor     0.521565\n",
       "Gaussian Process     0.563898\n",
       "MLP Neural Net       0.559904\n",
       "Deep Neural Net      0.562300"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = [{'LogReg' : logreg_acc_score,\n",
    "       'Perceptron' : percep_acc_score,\n",
    "       'PassiveAgressive' : pasagres_acc_score,\n",
    "       'Ridge' : ridge_acc_score,\n",
    "       'Linear SVM' : linsvm_acc_score,\n",
    "       'RBF SVM' : rbfsvm_acc_score,\n",
    "       'NuSupport SVC' : nusvc_acc_score,\n",
    "       'Decision Tree' : decision_tree_acc_score,\n",
    "       'Random Forest' : randforest_acc_score,\n",
    "       'Gradient Boosting' : gradboost_acc_score,\n",
    "       'AdaBoost' : adaboost_acc_score,\n",
    "       'Bagging' : bag_acc_score,\n",
    "       'Extra Trees' : extratrees_acc_score,\n",
    "       'Hist Gradient Boost' : histgrad_acc_score,\n",
    "       'Naive Bayes' : nbayes_acc_score,\n",
    "       'LDA' : lda_acc_score,\n",
    "       'QDA' : qda_acc_score,\n",
    "       'Nearest Neighbor' : nearneighboor_acc_score,\n",
    "       'Gaussian Process' : gausprocess_acc_score,\n",
    "       'MLP Neural Net' : mlp_acc_score,\n",
    "       'Deep Neural Net' : nn_acc_score}]\n",
    "df1 = pd.DataFrame(dat)\n",
    "df2 = df1.transpose()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27b083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
