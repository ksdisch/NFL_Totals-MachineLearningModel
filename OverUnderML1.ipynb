{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c845d9a7",
   "metadata": {},
   "source": [
    "# NFL Over Under Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a967339",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3f492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae053e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>team_home_full</th>\n",
       "      <th>team_home_abrv</th>\n",
       "      <th>team_home_combined</th>\n",
       "      <th>team_away_full</th>\n",
       "      <th>team_away_abrv</th>\n",
       "      <th>team_away_combined</th>\n",
       "      <th>...</th>\n",
       "      <th>team_away_dvoa_defense</th>\n",
       "      <th>team_away_dvoa_special</th>\n",
       "      <th>dvoa_overall_diff</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>team_home_dvoa_special_diff</th>\n",
       "      <th>team_away_dvoa_special_diff</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>11/17/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>NYG</td>\n",
       "      <td>NYG2013</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>28.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1834</td>\n",
       "      <td>12/16/2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>15</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE2012</td>\n",
       "      <td>San Francisco 49ers</td>\n",
       "      <td>SF</td>\n",
       "      <td>SF2012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1726</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>NYG</td>\n",
       "      <td>NYG2013</td>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>PHI</td>\n",
       "      <td>PHI2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>27.53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2459</td>\n",
       "      <td>10/24/2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB2010</td>\n",
       "      <td>Minnesota Vikings</td>\n",
       "      <td>MIN</td>\n",
       "      <td>MIN2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>30.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565</td>\n",
       "      <td>12/22/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA2013</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>ARI</td>\n",
       "      <td>ARI2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>29.46500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date  year  week        team_home_full team_home_abrv  \\\n",
       "0   1642  11/17/2013  2013    11       New York Giants            NYG   \n",
       "1   1834  12/16/2012  2012    15  New England Patriots             NE   \n",
       "2   1726   10/6/2013  2013     5       New York Giants            NYG   \n",
       "3   2459  10/24/2010  2010     7     Green Bay Packers             GB   \n",
       "4   1565  12/22/2013  2013    16      Seattle Seahawks            SEA   \n",
       "\n",
       "  team_home_combined       team_away_full team_away_abrv team_away_combined  \\\n",
       "0            NYG2013    Green Bay Packers             GB             GB2013   \n",
       "1             NE2012  San Francisco 49ers             SF             SF2012   \n",
       "2            NYG2013  Philadelphia Eagles            PHI            PHI2013   \n",
       "3             GB2010    Minnesota Vikings            MIN            MIN2010   \n",
       "4            SEA2013    Arizona Cardinals            ARI            ARI2013   \n",
       "\n",
       "   ...  team_away_dvoa_defense  team_away_dvoa_special  dvoa_overall_diff  \\\n",
       "0  ...                  -0.003                   0.071             -0.088   \n",
       "1  ...                  -0.015                   0.127              0.035   \n",
       "2  ...                  -0.028                   0.100             -0.300   \n",
       "3  ...                  -0.014                   0.067              0.352   \n",
       "4  ...                  -0.041                   0.108              0.274   \n",
       "\n",
       "   dvoa_weighted_diff  dvoa_dave_diff  team_home_dvoa_off_diff  \\\n",
       "0               0.037          -0.305                   -0.103   \n",
       "1               0.095           0.137                    0.044   \n",
       "2              -0.330          -0.446                   -0.078   \n",
       "3               0.379           0.266                   -0.126   \n",
       "4               0.239           0.126                   -0.210   \n",
       "\n",
       "  team_away_dvoa_off_diff  team_home_dvoa_special_diff  \\\n",
       "0                  -0.210                       -0.016   \n",
       "1                   0.198                        0.005   \n",
       "2                  -0.113                       -0.045   \n",
       "3                   0.020                        0.042   \n",
       "4                   0.238                        0.021   \n",
       "\n",
       "   team_away_dvoa_special_diff  comp_pace_avg  \n",
       "0                        0.016       28.65625  \n",
       "1                       -0.005       28.00000  \n",
       "2                        0.045       27.53500  \n",
       "3                       -0.042       30.20500  \n",
       "4                       -0.021       29.46500  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = Path('nfl.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ac0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>over_under</th>\n",
       "      <th>favorite_spread</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>team_home_off_pace_neutral</th>\n",
       "      <th>team_home_def_pace_neutral</th>\n",
       "      <th>team_home_off_pace_total</th>\n",
       "      <th>team_home_def_pace_total</th>\n",
       "      <th>team_home_comp_pace</th>\n",
       "      <th>...</th>\n",
       "      <th>team_away_dvoa_defense</th>\n",
       "      <th>team_away_dvoa_special</th>\n",
       "      <th>dvoa_overall_diff</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>team_home_dvoa_special_diff</th>\n",
       "      <th>team_away_dvoa_special_diff</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>31.08</td>\n",
       "      <td>29.50</td>\n",
       "      <td>27.74</td>\n",
       "      <td>26.82</td>\n",
       "      <td>28.785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>28.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>24.53</td>\n",
       "      <td>24.53</td>\n",
       "      <td>24.12</td>\n",
       "      <td>24.12</td>\n",
       "      <td>24.325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>31.08</td>\n",
       "      <td>29.50</td>\n",
       "      <td>27.74</td>\n",
       "      <td>26.82</td>\n",
       "      <td>28.785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>27.53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>31.53</td>\n",
       "      <td>31.36</td>\n",
       "      <td>29.92</td>\n",
       "      <td>27.67</td>\n",
       "      <td>30.120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>30.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>31.49</td>\n",
       "      <td>31.85</td>\n",
       "      <td>29.08</td>\n",
       "      <td>28.96</td>\n",
       "      <td>30.345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>29.46500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   week  over_under  favorite_spread  temperature  wind_mph  \\\n",
       "0    11        40.5             -3.0           61         2   \n",
       "1    15        47.5             -5.0           37         5   \n",
       "2     5        54.0             -1.5           69         9   \n",
       "3     7        44.5             -2.5           59         4   \n",
       "4    16        43.0             -9.0           50         6   \n",
       "\n",
       "   team_home_off_pace_neutral  team_home_def_pace_neutral  \\\n",
       "0                       31.08                       29.50   \n",
       "1                       24.53                       24.53   \n",
       "2                       31.08                       29.50   \n",
       "3                       31.53                       31.36   \n",
       "4                       31.49                       31.85   \n",
       "\n",
       "   team_home_off_pace_total  team_home_def_pace_total  team_home_comp_pace  \\\n",
       "0                     27.74                     26.82               28.785   \n",
       "1                     24.12                     24.12               24.325   \n",
       "2                     27.74                     26.82               28.785   \n",
       "3                     29.92                     27.67               30.120   \n",
       "4                     29.08                     28.96               30.345   \n",
       "\n",
       "   ...  team_away_dvoa_defense  team_away_dvoa_special  dvoa_overall_diff  \\\n",
       "0  ...                  -0.003                   0.071             -0.088   \n",
       "1  ...                  -0.015                   0.127              0.035   \n",
       "2  ...                  -0.028                   0.100             -0.300   \n",
       "3  ...                  -0.014                   0.067              0.352   \n",
       "4  ...                  -0.041                   0.108              0.274   \n",
       "\n",
       "   dvoa_weighted_diff  dvoa_dave_diff  team_home_dvoa_off_diff  \\\n",
       "0               0.037          -0.305                   -0.103   \n",
       "1               0.095           0.137                    0.044   \n",
       "2              -0.330          -0.446                   -0.078   \n",
       "3               0.379           0.266                   -0.126   \n",
       "4               0.239           0.126                   -0.210   \n",
       "\n",
       "   team_away_dvoa_off_diff  team_home_dvoa_special_diff  \\\n",
       "0                   -0.210                       -0.016   \n",
       "1                    0.198                        0.005   \n",
       "2                   -0.113                       -0.045   \n",
       "3                    0.020                        0.042   \n",
       "4                    0.238                        0.021   \n",
       "\n",
       "   team_away_dvoa_special_diff  comp_pace_avg  \n",
       "0                        0.016       28.65625  \n",
       "1                       -0.005       28.00000  \n",
       "2                        0.045       27.53500  \n",
       "3                       -0.042       30.20500  \n",
       "4                       -0.021       29.46500  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target variable and drop irrelevant columns for ML\n",
    "y = df['over_binary']\n",
    "X = df.drop(columns=['index','over_binary', 'over_under_diff', 'score_total', 'date', 'team_home_full', 'team_home_abrv', 'team_home_combined',\n",
    "                     'team_away_full', 'team_away_abrv', 'team_away_combined',\n",
    "                     'team_favorite_abrv', 'weather_detail', 'score_home', 'score_away', 'dome_binary',\n",
    "                     'humidity', 'year'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedc033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3821, 35)\n",
      "(1274, 35)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278dbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a Standard Scaler with the training data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# ccaling the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52a301",
   "metadata": {},
   "source": [
    "## ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928700a1",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c26370a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b98dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>416</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>296</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              416             238\n",
       "Actual Over               296             324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5808477237048666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61       654\n",
      "           1       0.58      0.52      0.55       620\n",
      "\n",
      "    accuracy                           0.58      1274\n",
      "   macro avg       0.58      0.58      0.58      1274\n",
      "weighted avg       0.58      0.58      0.58      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "logreg_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {logreg_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bef20a",
   "metadata": {},
   "source": [
    "### Suppor Vector Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0237b51",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9c0b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d6a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>420</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>298</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              420             234\n",
       "Actual Over               298             322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5824175824175825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61       654\n",
      "           1       0.58      0.52      0.55       620\n",
      "\n",
      "    accuracy                           0.58      1274\n",
      "   macro avg       0.58      0.58      0.58      1274\n",
      "weighted avg       0.58      0.58      0.58      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "linsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {linsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f8fff",
   "metadata": {},
   "source": [
    "#### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a702a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=2, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(gamma=2, C=1, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d374ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              654               0\n",
       "Actual Over               620               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5133437990580848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       654\n",
      "           1       0.00      0.00      0.00       620\n",
      "\n",
      "    accuracy                           0.51      1274\n",
      "   macro avg       0.26      0.50      0.34      1274\n",
      "weighted avg       0.26      0.51      0.35      1274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "rbfsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {rbfsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18d584",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed67526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tree.DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f89fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>357</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>320</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              357             297\n",
       "Actual Over               320             300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5156985871271585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54       654\n",
      "           1       0.50      0.48      0.49       620\n",
      "\n",
      "    accuracy                           0.52      1274\n",
      "   macro avg       0.51      0.51      0.51      1274\n",
      "weighted avg       0.52      0.52      0.52      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "decision_tree_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {decision_tree_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463d68a",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3821906",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=512, random_state=0)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76912074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>357</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>320</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              357             297\n",
       "Actual Over               320             300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5156985871271585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54       654\n",
      "           1       0.50      0.48      0.49       620\n",
      "\n",
      "    accuracy                           0.52      1274\n",
      "   macro avg       0.51      0.51      0.51      1274\n",
      "weighted avg       0.52      0.52      0.52      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "randforest_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {randforest_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63db9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03447723337344963, 'team_home_dvoa_off_diff'),\n",
       " (0.03419670219161477, 'team_away_dvoa_off_diff'),\n",
       " (0.03351893683318689, 'over_under'),\n",
       " (0.032916812660457664, 'comp_pace_avg'),\n",
       " (0.03189254892278897, 'dvoa_dave_diff'),\n",
       " (0.031000466465985112, 'team_away_dvoa_offense'),\n",
       " (0.030629748694849596, 'team_home_def_pace_total'),\n",
       " (0.030543006806451597, 'team_home_dvoa_defense'),\n",
       " (0.030453622107771375, 'team_away_dvoa_dave'),\n",
       " (0.03040526982371427, 'team_away_def_pace_total'),\n",
       " (0.030238706768467273, 'dvoa_weighted_diff'),\n",
       " (0.029697542073312624, 'team_home_dvoa_offense'),\n",
       " (0.02946231061909534, 'team_away_off_pace_total'),\n",
       " (0.02944099243966742, 'team_away_dvoa_defense'),\n",
       " (0.02924588501421387, 'team_away_off_pace_neutral'),\n",
       " (0.028940301490889265, 'dvoa_overall_diff'),\n",
       " (0.028710047185053187, 'team_away_comp_pace'),\n",
       " (0.02870442039907065, 'team_home_dvoa_dave'),\n",
       " (0.028629306105892847, 'team_home_def_pace_neutral'),\n",
       " (0.02860348207468023, 'team_away_def_pace_neutral'),\n",
       " (0.02855815388728402, 'team_home_off_pace_neutral'),\n",
       " (0.027943375081013744, 'team_home_off_pace_total'),\n",
       " (0.02793855374695221, 'temperature'),\n",
       " (0.027164592273170036, 'team_home_comp_pace'),\n",
       " (0.026539522324438358, 'team_home_dvoa_weighted'),\n",
       " (0.026372644985022176, 'team_away_dvoa_weighted'),\n",
       " (0.025989093203212545, 'team_away_dvoa_overall'),\n",
       " (0.025590475522434823, 'team_away_dvoa_special_diff'),\n",
       " (0.025519174134775384, 'favorite_spread'),\n",
       " (0.02549134458451414, 'week'),\n",
       " (0.025349569602914578, 'team_home_dvoa_special_diff'),\n",
       " (0.02531522638604164, 'team_home_dvoa_overall'),\n",
       " (0.023945744944566708, 'team_away_dvoa_special'),\n",
       " (0.02332716879790758, 'wind_mph'),\n",
       " (0.023248018475139454, 'team_home_dvoa_special')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c739b",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5519fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_features=5, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=50,\n",
    "   learning_rate=0.1, max_features=5, max_depth=3, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5074c406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>437</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>360</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              437             217\n",
       "Actual Over               360             260"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5470957613814756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60       654\n",
      "           1       0.55      0.42      0.47       620\n",
      "\n",
      "    accuracy                           0.55      1274\n",
      "   macro avg       0.55      0.54      0.54      1274\n",
      "weighted avg       0.55      0.55      0.54      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gradboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gradboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42782c78",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55d40b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.53, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators = 200,\n",
    "                                learning_rate = 0.53,\n",
    "                                random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e5aa839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>418</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>312</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              418             236\n",
       "Actual Over               312             308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5698587127158555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60       654\n",
      "           1       0.57      0.50      0.53       620\n",
      "\n",
      "    accuracy                           0.57      1274\n",
      "   macro avg       0.57      0.57      0.57      1274\n",
      "weighted avg       0.57      0.57      0.57      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "adaboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {adaboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0265167",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ada48207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_samples=200, n_estimators=2000, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BaggingClassifier(n_estimators = 2000,\n",
    "                               max_samples = 200, \n",
    "                               random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a8e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>437</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>366</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              437             217\n",
       "Actual Over               366             254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.542386185243328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60       654\n",
      "           1       0.54      0.41      0.47       620\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.54      0.54      0.53      1274\n",
      "weighted avg       0.54      0.54      0.53      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "bag_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {bag_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a38360",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e2c85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3b5ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>440</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>375</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              440             214\n",
       "Actual Over               375             245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5376766091051806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60       654\n",
      "           1       0.53      0.40      0.45       620\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.54      0.53      0.53      1274\n",
      "weighted avg       0.54      0.54      0.53      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nbayes_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nbayes_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b105186",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af7494c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = QuadraticDiscriminantAnalysis() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc286b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>289</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>286</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              289             365\n",
       "Actual Over               286             334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.489010989010989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.44      0.47       654\n",
      "           1       0.48      0.54      0.51       620\n",
      "\n",
      "    accuracy                           0.49      1274\n",
      "   macro avg       0.49      0.49      0.49      1274\n",
      "weighted avg       0.49      0.49      0.49      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "qda_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {qda_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633f368",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf34c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(4, leaf_size=30) # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52962dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>493</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>430</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              493             161\n",
       "Actual Over               430             190"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5361067503924647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.75      0.63       654\n",
      "           1       0.54      0.31      0.39       620\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.54      0.53      0.51      1274\n",
      "weighted avg       0.54      0.54      0.51      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nearneighboor_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nearneighboor_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ed1f8",
   "metadata": {},
   "source": [
    "### Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e8437fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(kernel=RBF(length_scale=1), random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianProcessClassifier(RBF(1.0), random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fc8cacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>362</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>328</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              362             292\n",
       "Actual Over               328             292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5133437990580848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.54       654\n",
      "           1       0.50      0.47      0.49       620\n",
      "\n",
      "    accuracy                           0.51      1274\n",
      "   macro avg       0.51      0.51      0.51      1274\n",
      "weighted avg       0.51      0.51      0.51      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gausprocess_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gausprocess_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6662a",
   "metadata": {},
   "source": [
    "### MLP Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1497e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(alpha=1, max_iter=1000, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77f92572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>412</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>322</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              412             242\n",
       "Actual Over               322             298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5572998430141287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59       654\n",
      "           1       0.55      0.48      0.51       620\n",
      "\n",
      "    accuracy                           0.56      1274\n",
      "   macro avg       0.56      0.56      0.55      1274\n",
      "weighted avg       0.56      0.56      0.55      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "mlp_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {mlp_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06163c25",
   "metadata": {},
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61bf765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.580848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.582418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.513344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.515699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.515699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.547096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.569859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.542386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.537677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.489011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <td>0.536107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process</th>\n",
       "      <td>0.513344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Neural Net</th>\n",
       "      <td>0.557300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "LogReg             0.580848\n",
       "Linear SVM         0.582418\n",
       "RBF SVM            0.513344\n",
       "Decision Tree      0.515699\n",
       "Random Forest      0.515699\n",
       "Gradient Boosting  0.547096\n",
       "AdaBoost           0.569859\n",
       "Bagging            0.542386\n",
       "Naive Bayes        0.537677\n",
       "QDA                0.489011\n",
       "Nearest Neighbor   0.536107\n",
       "Gaussian Process   0.513344\n",
       "MLP Neural Net     0.557300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = [{'LogReg' : logreg_acc_score,\n",
    "       'Linear SVM' : linsvm_acc_score,\n",
    "       'RBF SVM' : rbfsvm_acc_score,\n",
    "       'Decision Tree' : decision_tree_acc_score,\n",
    "       'Random Forest' : randforest_acc_score,\n",
    "       'Gradient Boosting' : gradboost_acc_score,\n",
    "       'AdaBoost' : adaboost_acc_score,\n",
    "       'Bagging' : bag_acc_score,\n",
    "       'Naive Bayes' : nbayes_acc_score,\n",
    "       'QDA' : qda_acc_score,\n",
    "       'Nearest Neighbor' : nearneighboor_acc_score,\n",
    "       'Gaussian Process' : gausprocess_acc_score,\n",
    "       'MLP Neural Net' : mlp_acc_score}]\n",
    "df1 = pd.DataFrame(dat)\n",
    "df2 = df1.transpose()\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
