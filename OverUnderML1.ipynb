{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfb6a91",
   "metadata": {},
   "source": [
    "# NFL Over Under Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782bc20",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3f492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae053e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>team_home_full</th>\n",
       "      <th>team_home_abrv</th>\n",
       "      <th>team_home_combined</th>\n",
       "      <th>team_away_full</th>\n",
       "      <th>team_away_abrv</th>\n",
       "      <th>team_away_combined</th>\n",
       "      <th>...</th>\n",
       "      <th>team_away_dvoa_defense</th>\n",
       "      <th>team_away_dvoa_special</th>\n",
       "      <th>dvoa_overall_diff</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>team_home_dvoa_special_diff</th>\n",
       "      <th>team_away_dvoa_special_diff</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>11/17/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>NYG</td>\n",
       "      <td>NYG2013</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>28.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1834</td>\n",
       "      <td>12/16/2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>15</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE2012</td>\n",
       "      <td>San Francisco 49ers</td>\n",
       "      <td>SF</td>\n",
       "      <td>SF2012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1726</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>NYG</td>\n",
       "      <td>NYG2013</td>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>PHI</td>\n",
       "      <td>PHI2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>27.53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2459</td>\n",
       "      <td>10/24/2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB2010</td>\n",
       "      <td>Minnesota Vikings</td>\n",
       "      <td>MIN</td>\n",
       "      <td>MIN2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>30.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565</td>\n",
       "      <td>12/22/2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA2013</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>ARI</td>\n",
       "      <td>ARI2013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>29.46500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date  year  week        team_home_full team_home_abrv  \\\n",
       "0   1642  11/17/2013  2013    11       New York Giants            NYG   \n",
       "1   1834  12/16/2012  2012    15  New England Patriots             NE   \n",
       "2   1726   10/6/2013  2013     5       New York Giants            NYG   \n",
       "3   2459  10/24/2010  2010     7     Green Bay Packers             GB   \n",
       "4   1565  12/22/2013  2013    16      Seattle Seahawks            SEA   \n",
       "\n",
       "  team_home_combined       team_away_full team_away_abrv team_away_combined  \\\n",
       "0            NYG2013    Green Bay Packers             GB             GB2013   \n",
       "1             NE2012  San Francisco 49ers             SF             SF2012   \n",
       "2            NYG2013  Philadelphia Eagles            PHI            PHI2013   \n",
       "3             GB2010    Minnesota Vikings            MIN            MIN2010   \n",
       "4            SEA2013    Arizona Cardinals            ARI            ARI2013   \n",
       "\n",
       "   ...  team_away_dvoa_defense  team_away_dvoa_special  dvoa_overall_diff  \\\n",
       "0  ...                  -0.003                   0.071             -0.088   \n",
       "1  ...                  -0.015                   0.127              0.035   \n",
       "2  ...                  -0.028                   0.100             -0.300   \n",
       "3  ...                  -0.014                   0.067              0.352   \n",
       "4  ...                  -0.041                   0.108              0.274   \n",
       "\n",
       "   dvoa_weighted_diff  dvoa_dave_diff  team_home_dvoa_off_diff  \\\n",
       "0               0.037          -0.305                   -0.103   \n",
       "1               0.095           0.137                    0.044   \n",
       "2              -0.330          -0.446                   -0.078   \n",
       "3               0.379           0.266                   -0.126   \n",
       "4               0.239           0.126                   -0.210   \n",
       "\n",
       "  team_away_dvoa_off_diff  team_home_dvoa_special_diff  \\\n",
       "0                  -0.210                       -0.016   \n",
       "1                   0.198                        0.005   \n",
       "2                  -0.113                       -0.045   \n",
       "3                   0.020                        0.042   \n",
       "4                   0.238                        0.021   \n",
       "\n",
       "   team_away_dvoa_special_diff  comp_pace_avg  \n",
       "0                        0.016       28.65625  \n",
       "1                       -0.005       28.00000  \n",
       "2                        0.045       27.53500  \n",
       "3                       -0.042       30.20500  \n",
       "4                       -0.021       29.46500  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = Path('nfl.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ac0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>over_under</th>\n",
       "      <th>favorite_spread</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dome_binary</th>\n",
       "      <th>team_home_off_pace_neutral</th>\n",
       "      <th>team_home_def_pace_neutral</th>\n",
       "      <th>...</th>\n",
       "      <th>team_away_dvoa_defense</th>\n",
       "      <th>team_away_dvoa_special</th>\n",
       "      <th>dvoa_overall_diff</th>\n",
       "      <th>dvoa_weighted_diff</th>\n",
       "      <th>dvoa_dave_diff</th>\n",
       "      <th>team_home_dvoa_off_diff</th>\n",
       "      <th>team_away_dvoa_off_diff</th>\n",
       "      <th>team_home_dvoa_special_diff</th>\n",
       "      <th>team_away_dvoa_special_diff</th>\n",
       "      <th>comp_pace_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>31.08</td>\n",
       "      <td>29.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>28.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>15</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>24.53</td>\n",
       "      <td>24.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>31.08</td>\n",
       "      <td>29.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>27.53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>31.53</td>\n",
       "      <td>31.36</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>30.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>31.49</td>\n",
       "      <td>31.85</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>29.46500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week  over_under  favorite_spread  temperature  wind_mph  humidity  \\\n",
       "0  2013    11        40.5             -3.0           61         2       100   \n",
       "1  2012    15        47.5             -5.0           37         5       100   \n",
       "2  2013     5        54.0             -1.5           69         9       100   \n",
       "3  2010     7        44.5             -2.5           59         4        96   \n",
       "4  2013    16        43.0             -9.0           50         6        94   \n",
       "\n",
       "   dome_binary  team_home_off_pace_neutral  team_home_def_pace_neutral  ...  \\\n",
       "0            0                       31.08                       29.50  ...   \n",
       "1            0                       24.53                       24.53  ...   \n",
       "2            0                       31.08                       29.50  ...   \n",
       "3            0                       31.53                       31.36  ...   \n",
       "4            0                       31.49                       31.85  ...   \n",
       "\n",
       "   team_away_dvoa_defense  team_away_dvoa_special  dvoa_overall_diff  \\\n",
       "0                  -0.003                   0.071             -0.088   \n",
       "1                  -0.015                   0.127              0.035   \n",
       "2                  -0.028                   0.100             -0.300   \n",
       "3                  -0.014                   0.067              0.352   \n",
       "4                  -0.041                   0.108              0.274   \n",
       "\n",
       "   dvoa_weighted_diff  dvoa_dave_diff  team_home_dvoa_off_diff  \\\n",
       "0               0.037          -0.305                   -0.103   \n",
       "1               0.095           0.137                    0.044   \n",
       "2              -0.330          -0.446                   -0.078   \n",
       "3               0.379           0.266                   -0.126   \n",
       "4               0.239           0.126                   -0.210   \n",
       "\n",
       "   team_away_dvoa_off_diff  team_home_dvoa_special_diff  \\\n",
       "0                   -0.210                       -0.016   \n",
       "1                    0.198                        0.005   \n",
       "2                   -0.113                       -0.045   \n",
       "3                    0.020                        0.042   \n",
       "4                    0.238                        0.021   \n",
       "\n",
       "   team_away_dvoa_special_diff  comp_pace_avg  \n",
       "0                        0.016       28.65625  \n",
       "1                       -0.005       28.00000  \n",
       "2                        0.045       27.53500  \n",
       "3                       -0.042       30.20500  \n",
       "4                       -0.021       29.46500  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target variable and drop irrelevant columns for ML\n",
    "y = df['over_binary']\n",
    "X = df.drop(columns=['index','over_binary', 'over_under_diff', 'score_total', 'date', 'team_home_full', 'team_home_abrv', 'team_home_combined',\n",
    "                     'team_away_full', 'team_away_abrv', 'team_away_combined',\n",
    "                     'team_favorite_abrv', 'weather_detail', 'score_home', 'score_away'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedc033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3821, 38)\n",
      "(1274, 38)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278dbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a Standard Scaler with the training data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# ccaling the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b236ed",
   "metadata": {},
   "source": [
    "## ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66bbdc",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c26370a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b98dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>402</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>295</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              402             252\n",
       "Actual Over               295             325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5706436420722135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.60       654\n",
      "           1       0.56      0.52      0.54       620\n",
      "\n",
      "    accuracy                           0.57      1274\n",
      "   macro avg       0.57      0.57      0.57      1274\n",
      "weighted avg       0.57      0.57      0.57      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "logreg_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {logreg_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c2453",
   "metadata": {},
   "source": [
    "### Suppor Vector Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7244242",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9c0b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d6a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>413</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>301</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              413             241\n",
       "Actual Over               301             319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5745682888540031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60       654\n",
      "           1       0.57      0.51      0.54       620\n",
      "\n",
      "    accuracy                           0.57      1274\n",
      "   macro avg       0.57      0.57      0.57      1274\n",
      "weighted avg       0.57      0.57      0.57      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "linsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {linsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896c42a",
   "metadata": {},
   "source": [
    "#### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a702a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=2, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(gamma=2, C=1, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f166e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              654               0\n",
       "Actual Over               620               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5133437990580848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       654\n",
      "           1       0.00      0.00      0.00       620\n",
      "\n",
      "    accuracy                           0.51      1274\n",
      "   macro avg       0.26      0.50      0.34      1274\n",
      "weighted avg       0.26      0.51      0.35      1274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "rbfsvm_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {rbfsvm_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a19c96e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed67526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tree.DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f89fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>379</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>327</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              379             275\n",
       "Actual Over               327             293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5274725274725275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56       654\n",
      "           1       0.52      0.47      0.49       620\n",
      "\n",
      "    accuracy                           0.53      1274\n",
      "   macro avg       0.53      0.53      0.53      1274\n",
      "weighted avg       0.53      0.53      0.53      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "decision_tree_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {decision_tree_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568c231",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3821906",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=512, random_state=0)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93dbb15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>379</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>327</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              379             275\n",
       "Actual Over               327             293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5274725274725275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56       654\n",
      "           1       0.52      0.47      0.49       620\n",
      "\n",
      "    accuracy                           0.53      1274\n",
      "   macro avg       0.53      0.53      0.53      1274\n",
      "weighted avg       0.53      0.53      0.53      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "randforest_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {randforest_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63db9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.033620281231553424, 'team_home_dvoa_off_diff'),\n",
       " (0.03338055630331891, 'over_under'),\n",
       " (0.03323617012491086, 'team_away_dvoa_off_diff'),\n",
       " (0.0317057897389507, 'comp_pace_avg'),\n",
       " (0.030050658075367137, 'team_away_dvoa_offense'),\n",
       " (0.02995903882277604, 'team_away_def_pace_total'),\n",
       " (0.029885084491529858, 'dvoa_dave_diff'),\n",
       " (0.029877481889946402, 'dvoa_weighted_diff'),\n",
       " (0.029638118138549822, 'team_away_dvoa_defense'),\n",
       " (0.029278047570728008, 'team_home_def_pace_total'),\n",
       " (0.029146716184581194, 'team_home_dvoa_defense'),\n",
       " (0.02904923194662683, 'team_away_dvoa_dave'),\n",
       " (0.028695770356763208, 'team_away_off_pace_total'),\n",
       " (0.028260419320778492, 'dvoa_overall_diff'),\n",
       " (0.02804017272093971, 'team_away_off_pace_neutral'),\n",
       " (0.02788914686773703, 'team_home_dvoa_offense'),\n",
       " (0.027642165905506295, 'team_home_dvoa_dave'),\n",
       " (0.02752468687667753, 'team_home_def_pace_neutral'),\n",
       " (0.02743618093956924, 'team_away_comp_pace'),\n",
       " (0.02737065425447305, 'team_away_def_pace_neutral'),\n",
       " (0.02725117793115859, 'team_home_off_pace_total'),\n",
       " (0.026749258217276656, 'team_home_off_pace_neutral'),\n",
       " (0.026505174050550043, 'temperature'),\n",
       " (0.026055870889235073, 'team_home_comp_pace'),\n",
       " (0.02554219175053424, 'team_away_dvoa_weighted'),\n",
       " (0.025491858630426918, 'week'),\n",
       " (0.025484151460251632, 'favorite_spread'),\n",
       " (0.024864161497189757, 'team_home_dvoa_weighted'),\n",
       " (0.02473379613514064, 'team_away_dvoa_overall'),\n",
       " (0.023994463133138848, 'team_away_dvoa_special_diff'),\n",
       " (0.023939598760581667, 'team_home_dvoa_special_diff'),\n",
       " (0.023808836186151178, 'team_home_dvoa_overall'),\n",
       " (0.02173051433980702, 'team_away_dvoa_special'),\n",
       " (0.02167991968277604, 'wind_mph'),\n",
       " (0.02167429573843031, 'team_home_dvoa_special'),\n",
       " (0.01823873107682686, 'humidity'),\n",
       " (0.017730623249741662, 'year'),\n",
       " (0.0028390055094990084, 'dome_binary')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2476b",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5519fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_features=5, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=50,\n",
    "   learning_rate=0.1, max_features=5, max_depth=3, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2baac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>428</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>340</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              428             226\n",
       "Actual Over               340             280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5557299843014128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.65      0.60       654\n",
      "           1       0.55      0.45      0.50       620\n",
      "\n",
      "    accuracy                           0.56      1274\n",
      "   macro avg       0.56      0.55      0.55      1274\n",
      "weighted avg       0.56      0.56      0.55      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gradboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gradboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ebf6b",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d942fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.53, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators = 200,\n",
    "                                learning_rate = 0.53,\n",
    "                                random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c749fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>414</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>315</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              414             240\n",
       "Actual Over               315             305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5643642072213501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       654\n",
      "           1       0.56      0.49      0.52       620\n",
      "\n",
      "    accuracy                           0.56      1274\n",
      "   macro avg       0.56      0.56      0.56      1274\n",
      "weighted avg       0.56      0.56      0.56      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "adaboost_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {adaboost_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03359713",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a51b72cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_samples=200, n_estimators=2000, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BaggingClassifier(n_estimators = 2000,\n",
    "                               max_samples = 200, \n",
    "                               random_state = 0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60094b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>436</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>364</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              436             218\n",
       "Actual Over               364             256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.543171114599686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60       654\n",
      "           1       0.54      0.41      0.47       620\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.54      0.54      0.53      1274\n",
      "weighted avg       0.54      0.54      0.54      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "bag_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {bag_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b31e61",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64c2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41cc1ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>433</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>373</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              433             221\n",
       "Actual Over               373             247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.533751962323391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.66      0.59       654\n",
      "           1       0.53      0.40      0.45       620\n",
      "\n",
      "    accuracy                           0.53      1274\n",
      "   macro avg       0.53      0.53      0.52      1274\n",
      "weighted avg       0.53      0.53      0.53      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nbayes_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nbayes_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9057f0",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b25e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = QuadraticDiscriminantAnalysis() # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d643bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>350</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>346</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              350             304\n",
       "Actual Over               346             274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.4897959183673469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52       654\n",
      "           1       0.47      0.44      0.46       620\n",
      "\n",
      "    accuracy                           0.49      1274\n",
      "   macro avg       0.49      0.49      0.49      1274\n",
      "weighted avg       0.49      0.49      0.49      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "qda_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {qda_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77265c",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "865dc654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(4, leaf_size=30) # no random_state parameter\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3f5ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>491</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>429</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              491             163\n",
       "Actual Over               429             191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5353218210361067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.75      0.62       654\n",
      "           1       0.54      0.31      0.39       620\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.54      0.53      0.51      1274\n",
      "weighted avg       0.54      0.54      0.51      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "nearneighboor_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {nearneighboor_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c46bb",
   "metadata": {},
   "source": [
    "### Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a915dda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(kernel=RBF(length_scale=1), random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianProcessClassifier(RBF(1.0), random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e2b21d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>349</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>324</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              349             305\n",
       "Actual Over               324             296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5062794348508635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53       654\n",
      "           1       0.49      0.48      0.48       620\n",
      "\n",
      "    accuracy                           0.51      1274\n",
      "   macro avg       0.51      0.51      0.51      1274\n",
      "weighted avg       0.51      0.51      0.51      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "gausprocess_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {gausprocess_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d188f6",
   "metadata": {},
   "source": [
    "### MLP Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef7d2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(alpha=1, max_iter=1000, random_state=0)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f367c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Under</th>\n",
       "      <th>Predicted Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Under</th>\n",
       "      <td>395</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Over</th>\n",
       "      <td>293</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Under  Predicted Over\n",
       "Actual Under              395             259\n",
       "Actual Over               293             327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5667189952904239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59       654\n",
      "           1       0.56      0.53      0.54       620\n",
      "\n",
      "    accuracy                           0.57      1274\n",
      "   macro avg       0.57      0.57      0.57      1274\n",
      "weighted avg       0.57      0.57      0.57      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({'Prediction':predictions, 'Actual':y_test}).reset_index(drop=True)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Under\", \"Actual Over\"], columns=[\"Predicted Under\", \"Predicted Over\"])\n",
    "mlp_acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {mlp_acc_score}\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7981977",
   "metadata": {},
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecf529f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.570644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.574568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.513344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.555730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.564364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.543171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.533752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process</th>\n",
       "      <td>0.506279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Neural Net</th>\n",
       "      <td>0.566719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "LogReg             0.570644\n",
       "Linear SVM         0.574568\n",
       "RBF SVM            0.513344\n",
       "Decision Tree      0.527473\n",
       "Random Forest      0.527473\n",
       "Gradient Boosting  0.555730\n",
       "AdaBoost           0.564364\n",
       "Bagging            0.543171\n",
       "Naive Bayes        0.533752\n",
       "QDA                0.489796\n",
       "Nearest Neighbor   0.535322\n",
       "Gaussian Process   0.506279\n",
       "MLP Neural Net     0.566719"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = [{'LogReg' : logreg_acc_score,\n",
    "       'Linear SVM' : linsvm_acc_score,\n",
    "       'RBF SVM' : rbfsvm_acc_score,\n",
    "       'Decision Tree' : decision_tree_acc_score,\n",
    "       'Random Forest' : randforest_acc_score,\n",
    "       'Gradient Boosting' : gradboost_acc_score,\n",
    "       'AdaBoost' : adaboost_acc_score,\n",
    "       'Bagging' : bag_acc_score,\n",
    "       'Naive Bayes' : nbayes_acc_score,\n",
    "       'QDA' : qda_acc_score,\n",
    "       'Nearest Neighbor' : nearneighboor_acc_score,\n",
    "       'Gaussian Process' : gausprocess_acc_score,\n",
    "       'MLP Neural Net' : mlp_acc_score}]\n",
    "df1 = pd.DataFrame(dat)\n",
    "df2 = df1.transpose()\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
